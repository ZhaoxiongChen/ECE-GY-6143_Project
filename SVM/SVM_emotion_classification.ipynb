{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM_emotion_classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2PsIcF_c1pmn"},"source":["# Support Vector Machine Model\n","\n","In our project, we expect to use Support Vector Machine to train [Cornell Dataset](https://www.cs.cornell.edu/people/pabo/movie-review-data/), as comparsion to the performance of LSTM(RNN) version."]},{"cell_type":"markdown","metadata":{"id":"38Tkm-nDgkmz"},"source":["## 1 Loading Data"]},{"cell_type":"markdown","metadata":{"id":"lj2wdliKgkm0"},"source":["Load tokenized clean corpus generated by `Data_cleaning_saving.ipynb` in Naive Bayes Section."]},{"cell_type":"code","metadata":{"id":"6nLHz4ongkm0","executionInfo":{"status":"ok","timestamp":1607970546191,"user_tz":300,"elapsed":502,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}}},"source":["import os\n","\n","def open_file(path):\n","    with open(path, mode='r', errors='replace') as f:\n","        sentence_list = f.readlines()\n","    return sentence_list\n","\n","pos_dir = 'data/pos_sample_tokenized.txt'\n","neg_dir = 'data/neg_sample_tokenized.txt'\n","all_dir = 'data/all_sample_tokenized.txt'\n","\n","# Open text with positive sentences\n","pos_list = open_file(pos_dir)\n","# Open text with negative sentences\n","neg_list = open_file(neg_dir)\n","# Open text with all sentences\n","all_list = open_file(all_dir)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jjhVzs9igkm1"},"source":["Build **bag of words** model for further training."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WL54gfCegkm1","executionInfo":{"status":"ok","timestamp":1607970549211,"user_tz":300,"elapsed":1926,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"75ffde02-4fb9-4f26-91d5-0e065ea56d1b"},"source":["import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Make labels for sentences\n","# 1: positive; 0: negative\n","y = np.hstack((np.ones(len(pos_list)),np.zeros(len(neg_list))))\n","print(f'Shape of label: {y.shape}')\n","\n","# Create vectorizer\n","vectorizer = CountVectorizer(input='content', lowercase=False)\n","\n","# Fit vectorizer with all processed tokens\n","# Transform them into sparse vector X\n","X = vectorizer.fit_transform(all_list).toarray()\n","print(f'Shape of vectorized dataset: {X.shape}')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Shape of label: (10655,)\n","Shape of vectorized dataset: (10655, 11952)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gI5m0PICgkm2"},"source":["Split training set and test set.\n","\n","The ratio is same as that in LSTM, which is 80% for training and 20% for testing."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riZEpKAQgkm3","executionInfo":{"status":"ok","timestamp":1607970551067,"user_tz":300,"elapsed":810,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"5fe4d71d-9a00-40b6-e5a5-45647a411823"},"source":["from sklearn.model_selection import train_test_split\n","\n","# Define dataset test split ratio\n","RANDOMNESS_SEED = 42\n","DATASET_TEST_SPLIT_RATIO = 0.2\n","\n","Xtr, Xts, ytr, yts = train_test_split(X, y, \n","                                      test_size=DATASET_TEST_SPLIT_RATIO, \n","                                      random_state=RANDOMNESS_SEED, \n","                                      shuffle=True)\n","\n","print(f'Number of features: {Xtr.shape[1]}')\n","print(f'Number of training texts: {Xtr.shape[0]}')\n","print(f'Number of training texts: {Xts.shape[0]}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Number of features: 11952\n","Number of training texts: 8524\n","Number of training texts: 2131\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sewe-xx_gkm4"},"source":["## 2 Support Vector Machine Implementation"]},{"cell_type":"markdown","metadata":{"id":"YHwU2YaGgkm4"},"source":["### 2.1 Feature Selection Method 1"]},{"cell_type":"markdown","metadata":{"id":"Ea1xwmxzgkm5"},"source":["#### 2.1.1 Feature Selection\n","\n","Selecting 3000 words as feature, based on appearing frequency in the overall data set."]},{"cell_type":"code","metadata":{"id":"PR_9jhJegkm5","executionInfo":{"status":"ok","timestamp":1607970553165,"user_tz":300,"elapsed":431,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}}},"source":["from sklearn import svm\n","from sklearn.metrics import precision_score, recall_score\n","import pandas as pd\n","\n","def show_features(feature_num, index, display_num, vectorizer=vectorizer):\n","    print(f'First 20 selected features in total of {feature_num} features:')\n","    j = 0 # List index\n","    for i in index[:display_num]:\n","        j += 1\n","        print(f'%02d. {vectorizer.get_feature_names()[i]}' % j)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtZbDIL2gkm6","executionInfo":{"status":"ok","timestamp":1607970565548,"user_tz":300,"elapsed":1074,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"10f07ac3-91e8-4c5c-c93a-96ab588137f2"},"source":["# Select 3000 words\n","feature_num_1 = 3000\n","\n","# Calculate frequency of each words in the overall dataset\n","frequency = np.sum(X, axis=0)\n","\n","# Find the indices of the most frequent words\n","indices_1 = np.argsort(frequency)[-1:(-1*feature_num_1-1):-1]\n","\n","# Training and testing data with only the selected feature\n","Xtr_1 = Xtr[:, indices_1]\n","Xts_1 = Xts[:, indices_1]\n","\n","# Show selected features\n","show_features(feature_num=feature_num_1, index=indices_1, display_num=20)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["First 20 selected features in total of 3000 features:\n","01. film\n","02. movi\n","03. like\n","04. one\n","05. make\n","06. stori\n","07. charact\n","08. time\n","09. comedi\n","10. good\n","11. even\n","12. much\n","13. work\n","14. perform\n","15. feel\n","16. way\n","17. get\n","18. littl\n","19. look\n","20. love\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"myerKmJegkm6"},"source":["#### 2.1.2 Fitting SVM\n","\n","The regularization coefficients we selected are 1, 5, 10, 50, 100, 200, 500, 1000, 1500, 2000."]},{"cell_type":"code","metadata":{"id":"D-N44okNUhL6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607976272890,"user_tz":300,"elapsed":5684379,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"2d595f50-6fdd-40b1-e1d6-6de690ddb288"},"source":["# List of regularization coefficients\n","list_C = [1, 5, 10, 50, 100, 200, 500, 1000, 1500, 2000]\n","\n","# Fitting SVMs with different regularization coefficients\n","classifiers = []\n","for C in list_C:\n","    svc = svm.SVC(C=C)\n","    svc.fit(Xtr_1, ytr)\n","    print(f'Fitting complete with C = {C}')\n","    classifiers.append(svc)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Fitting complete with C = 1\n","Fitting complete with C = 5\n","Fitting complete with C = 10\n","Fitting complete with C = 50\n","Fitting complete with C = 100\n","Fitting complete with C = 200\n","Fitting complete with C = 500\n","Fitting complete with C = 1000\n","Fitting complete with C = 1500\n","Fitting complete with C = 2000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qcSMiQpPgkm7"},"source":["Saving performance data.\n"]},{"cell_type":"code","metadata":{"id":"qRiWosqTZi-s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607982547726,"user_tz":300,"elapsed":4305762,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"bc88cc6b-8f94-4d24-fd4d-c6f5da35540f"},"source":["# Accuracy, recall and precision scores\n","nc = len(list_C)\n","score_train = np.zeros(nc)\n","score_test = np.zeros(nc)\n","recall_test = np.zeros(nc)\n","precision_test = np.zeros(nc)\n","\n","for count in range(nc):\n","    # Prediction\n","    yhat = classifiers[count].predict(Xts_1)\n","    \n","    # Results report\n","    score_train[count] = svc.score(Xtr_1, ytr)\n","    score_test[count]= svc.score(Xts_1, yts)\n","    recall_test[count] = recall_score(yts, yhat)\n","    precision_test[count] = precision_score(yts, yhat)\n","\n","    print(f'Report complete for SVM with C = {list_C[count]}')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Report complete for SVM with C = 1\n","Report complete for SVM with C = 5\n","Report complete for SVM with C = 10\n","Report complete for SVM with C = 50\n","Report complete for SVM with C = 100\n","Report complete for SVM with C = 200\n","Report complete for SVM with C = 500\n","Report complete for SVM with C = 1000\n","Report complete for SVM with C = 1500\n","Report complete for SVM with C = 2000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yJo6DNffgkm8"},"source":["#### 2.1.3 Performance Report"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZOm437TeKGz","executionInfo":{"status":"ok","timestamp":1607983451945,"user_tz":300,"elapsed":299,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"2adacf6a-3113-4190-8f4b-c0563ffcc835"},"source":["# Build performance matrix\n","matrix = np.matrix(np.c_[list_C, score_train, score_test, recall_test, precision_test])\n","# For better looking, save the matrix as pandas dataframe\n","models = pd.DataFrame(data = matrix, columns = ['C', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n","\n","print(f'Performance of SVM using {feature_num_1} words with highest frequency.')\n","print(models)\n","\n","print('\\nConfiguration that achieves the best performance')\n","best_index = models['Test Precision'].idxmax()\n","models.iloc[best_index, :]"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Performance of SVM using 3000 words with highest frequency.\n","        C  Train Accuracy  Test Accuracy  Test Recall  Test Precision\n","0     1.0        0.999531       0.695917     0.732276        0.745489\n","1     5.0        0.999531       0.695917     0.747201        0.738249\n","2    10.0        0.999531       0.695917     0.751866        0.730072\n","3    50.0        0.999531       0.695917     0.712687        0.712687\n","4   100.0        0.999531       0.695917     0.708022        0.704735\n","5   200.0        0.999531       0.695917     0.698694        0.700655\n","6   500.0        0.999531       0.695917     0.698694        0.697393\n","7  1000.0        0.999531       0.695917     0.698694        0.697393\n","8  1500.0        0.999531       0.695917     0.698694        0.697393\n","9  2000.0        0.999531       0.695917     0.698694        0.697393\n","\n","Configuration that achieves the best performance\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["C                 1.000000\n","Train Accuracy    0.999531\n","Test Accuracy     0.695917\n","Test Recall       0.732276\n","Test Precision    0.745489\n","Name: 0, dtype: float64"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"A7j-5CG4gjmQ"},"source":["### 2.2 Feature Selection Method 2"]},{"cell_type":"markdown","metadata":{"id":"6PUxW1YggjmQ"},"source":["#### 2.2.1 Feature Selection\n","\n","Selecting 3000 words as feature, based on Information Gain (IG) in the overall data set.\n","\n","Information Gain value is calculated in Naive Bayes section, saved as `IG.txt`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7PIUFJ0gjmR","executionInfo":{"status":"ok","timestamp":1607971258410,"user_tz":300,"elapsed":1789,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"911db24a-2eca-4a3b-f293-fe89634fca7f"},"source":["# Select 3000 words\n","feature_num_2 = 3000\n","\n","# Read IG value\n","IG_dir = 'data/IG.txt'\n","IG = []\n","with open(IG_dir, 'r') as f:\n","    IG = f.readlines()\n","IG = np.array(IG).astype(np.float64)\n","\n","# Find the indices of the most frequent words\n","indices_2 = np.argsort(IG)[-1:(-1*feature_num_2-1):-1]\n","\n","# Training and testing data with only the selected feature\n","Xtr_2 = Xtr[:, indices_2]\n","Xts_2 = Xts[:, indices_2]\n","\n","# Show selected features\n","show_features(feature_num=feature_num_2, index=indices_2, display_num=20)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["First 20 selected features in total of 3000 features:\n","01. bad\n","02. bore\n","03. beauti\n","04. dull\n","05. perform\n","06. wast\n","07. joke\n","08. movi\n","09. heart\n","10. move\n","11. best\n","12. human\n","13. cultur\n","14. titl\n","15. film\n","16. examin\n","17. flat\n","18. entertain\n","19. unfunni\n","20. funni\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MQllGzC2gjmR"},"source":["#### 2.2.2 Fitting SVM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gz1JzIKBgjmS","executionInfo":{"status":"ok","timestamp":1607975909756,"user_tz":300,"elapsed":4651407,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"7cacd58b-77db-4bc8-9e26-4612af753e61"},"source":["# List of regularization coefficients\n","list_C = [1, 5, 10, 50, 100, 200, 500, 1000, 1500, 2000]\n","\n","# Fitting SVMs with different regularization coefficients\n","classifiers_2 = []\n","for C in list_C:\n","    svc = svm.SVC(C=C)\n","    svc.fit(Xtr_2, ytr)\n","    print(f'Fitting complete with C = {C}')\n","    classifiers_2.append(svc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting complete with C = 1\n","Fitting complete with C = 5\n","Fitting complete with C = 10\n","Fitting complete with C = 50\n","Fitting complete with C = 100\n","Fitting complete with C = 200\n","Fitting complete with C = 500\n","Fitting complete with C = 1000\n","Fitting complete with C = 1500\n","Fitting complete with C = 2000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1InxMiOegjmS"},"source":["Saving performance data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HboLg8ggjmS","executionInfo":{"status":"ok","timestamp":1607982258787,"user_tz":300,"elapsed":4011714,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"097d547c-7a54-4bde-f8c0-333fa48ea3da"},"source":["# Accuracy, recall and precision scores\n","nc = len(list_C)\n","score_train_2 = np.zeros(nc)\n","score_test_2 = np.zeros(nc)\n","recall_test_2 = np.zeros(nc)\n","precision_test_2 = np.zeros(nc)\n","\n","for count in range(nc):\n","    # Prediction\n","    yhat = classifiers_2[count].predict(Xts_2)\n","    \n","    # Results report\n","    score_train_2[count] = svc.score(Xtr_2, ytr)\n","    score_test_2[count]= svc.score(Xts_2, yts)\n","    recall_test_2[count] = recall_score(yts, yhat)\n","    precision_test_2[count] = precision_score(yts, yhat)\n","\n","    print(f'Report complete for SVM with C = {list_C[count]}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Report complete for SVM with C = 1\n","Report complete for SVM with C = 5\n","Report complete for SVM with C = 10\n","Report complete for SVM with C = 50\n","Report complete for SVM with C = 100\n","Report complete for SVM with C = 200\n","Report complete for SVM with C = 500\n","Report complete for SVM with C = 1000\n","Report complete for SVM with C = 1500\n","Report complete for SVM with C = 2000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4A9fi9yugjmT"},"source":["#### 2.2.3 Performance Report"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrPZ_CuCnXvH","executionInfo":{"status":"ok","timestamp":1607983582805,"user_tz":300,"elapsed":308,"user":{"displayName":"ZX Chen","photoUrl":"","userId":"01110524324204802966"}},"outputId":"243f791e-591f-412c-f9e1-65af63c58095"},"source":["# Build performance matrix\n","matrix_2 = np.matrix(np.c_[list_C, score_train_2, score_test_2, recall_test_2, precision_test_2])\n","# For better looking, save the matrix as pandas dataframe\n","models_2 = pd.DataFrame(data = matrix_2, columns = ['C', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n","\n","print(f'Performance of SVM using {feature_num_2} words with highest information gain.')\n","print(models_2)\n","\n","print('\\nConfiguration that achieves the best performance')\n","best_index_2 = models_2['Test Precision'].idxmax()\n","models_2.iloc[best_index_2, :]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Performance of SVM using 3000 words with highest information gain.\n","        C  Train Accuracy  Test Accuracy  Test Recall  Test Precision\n","0     1.0        0.995307       0.693102     0.753731        0.756554\n","1     5.0        0.995307       0.693102     0.756530        0.750926\n","2    10.0        0.995307       0.693102     0.747201        0.743043\n","3    50.0        0.995307       0.693102     0.721082        0.693896\n","4   100.0        0.995307       0.693102     0.720149        0.686833\n","5   200.0        0.995307       0.693102     0.720149        0.685613\n","6   500.0        0.995307       0.693102     0.720149        0.685613\n","7  1000.0        0.995307       0.693102     0.720149        0.685613\n","8  1500.0        0.995307       0.693102     0.720149        0.685613\n","9  2000.0        0.995307       0.693102     0.720149        0.685613\n","\n","Configuration that achieves the best performance\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["C                 1.000000\n","Train Accuracy    0.995307\n","Test Accuracy     0.693102\n","Test Recall       0.753731\n","Test Precision    0.756554\n","Name: 0, dtype: float64"]},"metadata":{"tags":[]},"execution_count":33}]}]}